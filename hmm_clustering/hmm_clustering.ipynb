{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Markov Model (HMM) Clustering Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train an HMM for Each User Sequence\n",
    "\n",
    "- Independently train an HMM with m states for each of the N user sequences.\n",
    "- Initialize the HMM parameters (means and covariances) using k-means clustering.\n",
    "- Initialize initial state and transition probabilities uniformly.\n",
    "- Optimize the HMM parameters using the Baum-Welch algorithm.\n",
    "\n",
    "2. Compute Log-Likelihood Matrix and Perform Clustering\n",
    "\n",
    "- For all N sequences, compute the log-likelihood of each sequence under every other sequence's HMM (resulting in an N √ó N matrix)\n",
    "- Use the log-likelihood values to compute similarity distances\n",
    "- Perform hierarchical clustering based on these distances to form K clusters\n",
    "\n",
    "3. Train Composite HMMs for Each Cluster\n",
    "\n",
    "- For each cluster, train a new HMM on the sequences within the cluster.\n",
    "- Follow the same training procedure as in Step 1: initialize with k-means and optimize using the Baum-Welch algorithm.\n",
    "\n",
    "4. Determine the Optimal Number of Clusters (ùêæ)\n",
    "\n",
    "- Explore different values of K (number of clusters) and m (number of HMM states).\n",
    "- Select the combination that yields the lowest AIC or BIC score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Train an HMM for Each User Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_data_based_correction(start_probs, alpha=0.01):\n",
    "    \"\"\"\n",
    "    Adjusts zero initial state probabilities with alpha, then normalizes the distribution.\n",
    "    \"\"\"\n",
    "    zero_indices = np.where(start_probs == 0)[0]\n",
    "    nonzero_indices = np.where(start_probs > 0)[0]\n",
    "\n",
    "    if len(zero_indices) > 0:\n",
    "        nonzero_sum = np.sum(start_probs[nonzero_indices])\n",
    "        start_probs[zero_indices] = alpha\n",
    "        start_probs[nonzero_indices] = (start_probs[nonzero_indices] / nonzero_sum) * (1 - len(zero_indices) * alpha)\n",
    "        start_probs /= np.sum(start_probs)\n",
    "\n",
    "    return start_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_transition_matrix(transmat, alpha=0.01):\n",
    "    \"\"\"\n",
    "    Normalizes each row; replaces all-zero rows with uniform distribution.\n",
    "    \"\"\"\n",
    "    corrected = transmat.copy()\n",
    "    for i in range(corrected.shape[0]):\n",
    "        if np.sum(corrected[i]) == 0:\n",
    "            corrected[i] = np.full(corrected.shape[1], 1.0 / corrected.shape[1])\n",
    "        else:\n",
    "            corrected[i] = corrected[i] / np.sum(corrected[i])\n",
    "    return corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_individual_hmms(patient_sequences, num_states=4, num_iter=100, random_state=42, laplace_alpha=0.001):\n",
    "    \"\"\"\n",
    "    Trains one HMM per user using unsupervised learning with K-Means-based initialization.\n",
    "\n",
    "    Returns:\n",
    "    - trained_hmms: Dictionary mapping user ID to trained HMM model.\n",
    "    \"\"\"\n",
    "        \n",
    "    trained_hmms = {}\n",
    "\n",
    "    for patient, sequence in patient_sequences.items():\n",
    "        if sequence.shape[0] < num_states:\n",
    "            print(f\"Skipping user {patient} due to insufficient data.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            kmeans = KMeans(n_clusters=num_states, n_init=10, init='k-means++', random_state=random_state)\n",
    "            labels = kmeans.fit_predict(sequence)\n",
    "            cluster_means = kmeans.cluster_centers_\n",
    "        except ValueError:\n",
    "            print(f\"K-means failed for user {patient}. Using mean-based initialization.\")\n",
    "            cluster_means = np.mean(sequence, axis=0, keepdims=True) + np.random.randn(num_states, sequence.shape[1]) * 0.01\n",
    "            labels = np.zeros(sequence.shape[0], dtype=int)\n",
    "\n",
    "        cluster_covariances = np.zeros((num_states, sequence.shape[1]))\n",
    "        for i in range(num_states):\n",
    "            cluster_data = sequence[labels == i]\n",
    "            if cluster_data.shape[0] > 1:\n",
    "                cluster_covariances[i] = np.var(cluster_data, axis=0)\n",
    "            else:\n",
    "                cluster_covariances[i] = np.var(sequence, axis=0)\n",
    "\n",
    "        cluster_covariances = np.clip(cluster_covariances, 1e-2, None)\n",
    "\n",
    "        model = hmm.GaussianHMM(n_components=num_states, covariance_type=\"diag\",\n",
    "                                n_iter=num_iter, init_params='', random_state=random_state)\n",
    "        model.startprob_ = np.full(num_states, 1 / num_states)\n",
    "        model.transmat_ = np.full((num_states, num_states), 1 / num_states)\n",
    "        model.means_ = cluster_means\n",
    "        model.covars_ = cluster_covariances\n",
    "        model.fit(sequence)\n",
    "\n",
    "        model.startprob_ = apply_data_based_correction(model.startprob_, alpha=laplace_alpha)\n",
    "        model.transmat_ = correct_transition_matrix(model.transmat_, alpha=laplace_alpha)\n",
    "\n",
    "        trained_hmms[patient] = model\n",
    "\n",
    "    return trained_hmms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Compute Log-Likelihood Matrix and Perform Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_likelihood_matrix(trained_hmms, patient_sequences):\n",
    "    \"\"\"\n",
    "    Computes the pairwise log-likelihood matrix L_ij = log P(S_j | M_i),\n",
    "    where M_i is the model of user i and S_j is the sequence of user j.\n",
    "\n",
    "    Returns:\n",
    "    - log_likelihood_matrix: N x N matrix\n",
    "    - patient_list: Ordered list of user IDs\n",
    "    \"\"\"\n",
    "    patient_list = list(patient_sequences.keys())\n",
    "    num_patients = len(patient_list)\n",
    "    log_likelihood_matrix = np.zeros((num_patients, num_patients))\n",
    "\n",
    "    for i, patient_i in enumerate(patient_list):\n",
    "        model_i = trained_hmms[patient_i]\n",
    "        for j, patient_j in enumerate(patient_list):\n",
    "            sequence_j = patient_sequences[patient_j]\n",
    "            log_likelihood_matrix[i, j] = model_i.score(sequence_j)\n",
    "\n",
    "    return log_likelihood_matrix, patient_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_symmetric_distance(log_likelihood_matrix):\n",
    "    \"\"\"\n",
    "    Converts the log-likelihood matrix into a symmetric distance matrix using:\n",
    "    D_ij = -0.5 * (L_ij + L_ji)\n",
    "\n",
    "    Returns:\n",
    "    - distance_matrix: Symmetric distance matrix\n",
    "    \"\"\"\n",
    "    num_patients = log_likelihood_matrix.shape[0]\n",
    "    distance_matrix = np.zeros((num_patients, num_patients))\n",
    "\n",
    "    for i in range(num_patients):\n",
    "        for j in range(num_patients):\n",
    "            distance_matrix[i, j] = - 0.5 * (log_likelihood_matrix[i, j] + log_likelihood_matrix[j, i])\n",
    "    distance_matrix -= np.min(distance_matrix)\n",
    "    np.fill_diagonal(distance_matrix, 0)\n",
    "    return distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_users_using_distance(distance_matrix, patient_list, num_clusters=2):\n",
    "    \"\"\"\n",
    "    Performs hierarchical clustering using the symmetric distance matrix.\n",
    "\n",
    "    Returns:\n",
    "    - cluster_labels: Cluster label array\n",
    "    - user_clusters: Mapping from user ID to cluster ID\n",
    "    - patient_mapping: Mapping from dendrogram index to user ID\n",
    "    \"\"\"\n",
    "    distance_matrix = ssd.squareform(distance_matrix)\n",
    "    linkage_matrix = linkage(distance_matrix, method='complete')\n",
    "    max_d = linkage_matrix[-(num_clusters-1), 2]\n",
    "    \n",
    "    patient_mapping = {i + 1: patient_list[i] for i in range(len(patient_list))}\n",
    "    labeled_patient_list = list(patient_mapping.keys())\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    dendro = sch.dendrogram(linkage_matrix, labels=labeled_patient_list, color_threshold=max_d)\n",
    "    plt.title(\"Hierarchical Clustering Dendrogram\")\n",
    "    plt.xlabel(\"Samples (Indexed)\")\n",
    "    plt.ylabel(\"Distance\")\n",
    "    plt.show()\n",
    "\n",
    "    cluster_labels = fcluster(linkage_matrix, num_clusters, criterion='maxclust')\n",
    "    user_clusters = {patient_list[i]: cluster_labels[i] for i in range(len(patient_list))}\n",
    "    \n",
    "    return cluster_labels, user_clusters, patient_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train Composite HMMs for Each Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_composite_hmms(user_clusters, patient_sequences, num_states=4, num_iter=100, random_state=42, laplace_alpha=0.01):\n",
    "    \"\"\"\n",
    "    Trains a composite HMM for each cluster using all user sequences assigned to the cluster.\n",
    "\n",
    "    Returns:\n",
    "    - composite_hmms: Mapping from cluster ID to trained composite HMM\n",
    "    \"\"\"\n",
    "    clusters = {}\n",
    "    for user, cluster in user_clusters.items():\n",
    "        clusters.setdefault(cluster, []).append(patient_sequences[user])\n",
    "\n",
    "    composite_hmms = {}\n",
    "    for cluster, sequences in clusters.items():\n",
    "        all_sequences = np.concatenate(sequences)\n",
    "\n",
    "        if all_sequences.shape[0] < num_states:\n",
    "            print(f\"Skipping cluster {cluster} due to insufficient data.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            kmeans = KMeans(n_clusters=num_states, n_init=10, init='k-means++', random_state=random_state)\n",
    "            labels = kmeans.fit_predict(all_sequences)\n",
    "            cluster_means = kmeans.cluster_centers_\n",
    "        except ValueError:\n",
    "            print(f\"K-means failed for cluster {cluster}. Using mean-based initialization.\")\n",
    "            cluster_means = np.mean(all_sequences, axis=0, keepdims=True) + np.random.randn(num_states, all_sequences.shape[1]) * 0.01\n",
    "            labels = np.zeros(all_sequences.shape[0], dtype=int)\n",
    "\n",
    "        cluster_covariances = np.zeros((num_states, all_sequences.shape[1]))\n",
    "        for i in range(num_states):\n",
    "            cluster_data = all_sequences[labels == i]\n",
    "            if cluster_data.shape[0] > 1:\n",
    "                cluster_covariances[i] = np.var(cluster_data, axis=0)\n",
    "            else:\n",
    "                cluster_covariances[i] = np.var(all_sequences, axis=0)\n",
    "\n",
    "        cluster_covariances = np.clip(cluster_covariances, 1e-2, None)\n",
    "\n",
    "        model = hmm.GaussianHMM(n_components=num_states, covariance_type=\"diag\",\n",
    "                                n_iter=num_iter, init_params='', random_state=random_state)\n",
    "        model.startprob_ = np.full(num_states, 1 / num_states)\n",
    "        model.transmat_ = np.full((num_states, num_states), 1 / num_states)\n",
    "        model.means_ = cluster_means\n",
    "        model.covars_ = cluster_covariances\n",
    "        model.fit(all_sequences)\n",
    "        \n",
    "        model.startprob_ = apply_data_based_correction(model.startprob_, alpha=laplace_alpha)\n",
    "        model.transmat_ = correct_transition_matrix(model.transmat_, alpha=laplace_alpha)\n",
    "\n",
    "        composite_hmms[cluster] = model\n",
    "        \n",
    "    return composite_hmms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Determine the Optimal Number of Clusters (ùêæ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_aic_bic_extended(patient_sequences, k_values, num_states_values, num_iter=100):\n",
    "    \"\"\"\n",
    "    Computes AIC and BIC scores for various combinations of (num_states, num_clusters),\n",
    "    and identifies the optimal combination.\n",
    "\n",
    "    Returns:\n",
    "    - best_params_aic: Tuple of best (num_states, num_clusters) by AIC\n",
    "    - best_params_bic: Tuple of best (num_states, num_clusters) by BIC\n",
    "    - aic_matrix: AIC values as a 2D matrix\n",
    "    - bic_matrix: BIC values as a 2D matrix\n",
    "    - num_states_list: List of tested state sizes\n",
    "    - k_list: List of tested cluster sizes\n",
    "    \"\"\"\n",
    "    aic_matrix = np.zeros((len(num_states_values), len(k_values)))\n",
    "    bic_matrix = np.zeros((len(num_states_values), len(k_values)))\n",
    "    \n",
    "    num_states_list = list(num_states_values)\n",
    "    k_list = list(k_values)\n",
    "\n",
    "    for i, num_states in enumerate(num_states_list):\n",
    "        print(f\"\\n Testing num_states = {num_states}\")\n",
    "        trained_hmms = train_individual_hmms(patient_sequences, num_states=num_states, num_iter=num_iter)\n",
    "        logL_matrix, patient_list = compute_log_likelihood_matrix(trained_hmms, patient_sequences)\n",
    "        distance_matrix = compute_symmetric_distance(logL_matrix)\n",
    "\n",
    "        for j, k in enumerate(k_list):\n",
    "            print(f\"  - Testing K = {k}\")\n",
    "            _, user_clusters, _ = cluster_users_using_distance(distance_matrix, patient_list, num_clusters=k)\n",
    "            composite_hmms = train_composite_hmms(user_clusters, patient_sequences, num_states=num_states, num_iter=num_iter)\n",
    "\n",
    "            total_log_likelihood = 0\n",
    "            total_params = 0\n",
    "\n",
    "            for cluster_id, model in composite_hmms.items():\n",
    "                total_log_likelihood += model.score(np.vstack([patient_sequences[p] for p in user_clusters if user_clusters[p] == cluster_id]))\n",
    "                N = model.n_components\n",
    "                D = model.means_.shape[1]\n",
    "                num_params = (N - 1) + N * (N - 1) + 2 * N * D # startprob + transmat + mean + var\n",
    "                total_params += num_params\n",
    "\n",
    "            num_samples = sum(seq.shape[0] for seq in patient_sequences.values())\n",
    "\n",
    "            aic = 2 * total_params - 2 * total_log_likelihood\n",
    "            bic = total_params * np.log(num_samples) - 2 * total_log_likelihood\n",
    "\n",
    "            aic_matrix[i, j] = aic\n",
    "            bic_matrix[i, j] = bic\n",
    "\n",
    "            print(f\"    K={k}, AIC={aic:.2f}, BIC={bic:.2f}\")\n",
    "\n",
    "    best_idx_aic = np.unravel_index(np.argmin(aic_matrix), aic_matrix.shape)\n",
    "    best_idx_bic = np.unravel_index(np.argmin(bic_matrix), bic_matrix.shape)\n",
    "\n",
    "    best_params_aic = (num_states_list[best_idx_aic[0]], k_list[best_idx_aic[1]])\n",
    "    best_params_bic = (num_states_list[best_idx_bic[0]], k_list[best_idx_bic[1]])\n",
    "\n",
    "    return best_params_aic, best_params_bic, aic_matrix, bic_matrix, num_states_list, k_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(matrix, x_labels, y_labels, title, cmap=\"coolwarm\"):\n",
    "    \"\"\"\n",
    "    Plots a heatmap of the given matrix with labeled axes.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(matrix, annot=True, fmt=\".1f\", xticklabels=x_labels, yticklabels=y_labels, cmap=cmap, linewidths=0.5)\n",
    "    plt.xlabel(\"Number of Clusters (K)\")\n",
    "    plt.ylabel(\"Hidden States (num_states)\")\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Full Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    k_values = range(2, 6)\n",
    "    num_states_values = range(2, 5)\n",
    "\n",
    "    best_params_aic, best_params_bic, aic_matrix, bic_matrix, num_states_list, k_list = compute_aic_bic_extended(\n",
    "        patient_sequences, k_values, num_states_values, num_iter=100\n",
    "    )\n",
    "\n",
    "    plot_heatmap(aic_matrix, k_list, num_states_list, \"AIC Scores for (num_states, K)\")\n",
    "    plot_heatmap(bic_matrix, k_list, num_states_list, \"BIC Scores for (num_states, K)\")\n",
    "\n",
    "    print(f\"Best (num_states, K) based on AIC: {best_params_aic}\")\n",
    "    print(f\"Best (num_states, K) based on BIC: {best_params_bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Set based on best AIC/BIC result\n",
    "    num_states = 4\n",
    "    num_clusters = 2\n",
    "\n",
    "    trained_hmms = train_individual_hmms(patient_sequences, num_states=num_states)\n",
    "\n",
    "    log_likelihood_matrix, patient_list = compute_log_likelihood_matrix(trained_hmms, patient_sequences)\n",
    "    distance_matrix = compute_symmetric_distance(log_likelihood_matrix)\n",
    "\n",
    "    cluster_labels, user_clusters, patient_mapping = cluster_users_using_distance(\n",
    "        distance_matrix, patient_list, num_clusters=num_clusters\n",
    "    )\n",
    "    df_user_clusters = save_user_clusters(user_clusters)\n",
    "    cluster_hmms = train_composite_hmms(user_clusters, patient_sequences, num_states=num_states, num_iter=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HMM Parameter Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_cluster_hmms(cluster_hmms):\n",
    "    cluster_labels = {\n",
    "        1: \"Sustained Engagers\",\n",
    "        2: \"Sporadic Engagers\"\n",
    "    }\n",
    "\n",
    "    for cluster_id, model in cluster_hmms.items():\n",
    "        # Order states by descending sum of their means\n",
    "        state_order = np.argsort(model.means_.sum(axis=1))[::-1]\n",
    "        \n",
    "        sorted_transmat = model.transmat_[state_order][:, state_order]\n",
    "        sorted_means = model.means_[state_order]\n",
    "        sorted_covars = model.covars_[state_order]\n",
    "\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "        sns.heatmap(sorted_transmat, annot=True, cmap=\"Blues\", fmt=\".2f\", ax=axes[0])\n",
    "        axes[0].set_title(f\"{cluster_labels.get(cluster_id, f'Cluster {cluster_id}')} - Transition Matrix\", fontsize=title_fontsize)\n",
    "        axes[0].set_xlabel(\"To State\")\n",
    "        axes[0].set_ylabel(\"From State\")\n",
    "\n",
    "        sns.heatmap(sorted_means, annot=True, cmap=\"Greens\", fmt=\".2f\", ax=axes[1])\n",
    "        axes[1].set_title(f\"{cluster_labels.get(cluster_id, f'Cluster {cluster_id}')} - State Mean\", fontsize=title_fontsize)\n",
    "        axes[1].set_xlabel(\"Feature Index\")\n",
    "        axes[1].set_ylabel(\"State\")\n",
    "\n",
    "        diag_covars = np.array([np.diag(cov) for cov in sorted_covars])\n",
    "        sns.heatmap(diag_covars, annot=True, cmap=\"Reds\", fmt=\".2e\", ax=axes[2])\n",
    "        axes[2].set_title(f\"{cluster_labels.get(cluster_id, f'Cluster {cluster_id}')} - State Covariance\", fontsize=title_fontsize)\n",
    "        axes[2].set_xlabel(\"Feature Index\")\n",
    "        axes[2].set_ylabel(\"State\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (newHMM)",
   "language": "python",
   "name": "hmm2025"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
